# Hadoop 集群配置

## 目的

该文档描述了如何从很少的节点到上千节点集群的安装和配置，如果仅仅是简单使用Hadoop，你首先应该想到在单台主机撒过安装它。

这篇文档并不包含像安全和高可用这些高级特性。

## 前置条件

* 安装Java
* 从Apache镜像下载稳定版的Hadoop

## 安装

安装Hadoop集群通常设计解压软件，你可以根据自己的操作系统，安装适当的压缩软件。

通常，集群中只有一个主机会被设计为`NameNode`名称节点作为其他主机的`ResourceManager`资源管理器，他们都是管理节点，其他服务（像Web程序代理服务和MapReduce Job History服务）都会运行在他们上面，依赖他们进行加载。

集群中其他主机的行为作为`DataNode`和`NodeManager`，他们都是从节点。

## 配置Hadoop的非安全模式

Hadoop的java配置通过两类非常重要的配置文件进行驱动：

* 只读的默认配置 - `core-default.xml`,`hdfs-default.xml`,`yarn-default.xml`以及`mapred-default.xml`。
* 个人的特殊配置 - `etc/hadoop/core-site.xml`,`etc/hadoop/hdfs-site.xml`,`yarn-site.xml`以及`mapred-site.xml`

另外，你可以在发行目录`bin`下找到你可以控制的脚本，通过`etc/hadoop/hadoop-env.sh`和`etc/hadoop/yarn-env.sh`配置一些个人特殊的值。

你需要配置Hadoop守护进程执行时的`environment`，以及为Hadoop守护进程设置配置参数。

HDFS守护进程有NameNode,SecondaryNameNode和DataNode。YARN守护进程有ResourceManager,NodeManager和WebAppProxy。如果使用了MapReduce，那么MapReduce Job History Server也要运行。对于庞大的安装情况，他们都会运行在不同的主机上。

### 配置Hadoop守护进程的环境

管理员应该使用`etc/hadoop/hadoop-env.sh`,`etc/hadoop/mapred-env.sh`,`etc/hadoop/yarn-env.sh`脚本自定义Hadoop守护进程的环境。

最后，你应该使`JAVA_HOME`在每一个远程节点上配置正确。

管理员可以使用下表中的配置选项配置个人的守护程序：

| 守护程序                      | 环境变量                      |
| ----------------------------- | ----------------------------- |
| NameNode                      | HADOOP_NAMENODE_OPTS          |
| DataNode                      | HADOOP_DATANODE_OPTS          |
| Secondary NameNode            | HADOOP_SECONDARYNAMENODE_OPTS |
| ResourceManager               | YARN_RESOURCEMANAGER_OPTS     |
| NodeManager                   | YARN_NODEMANAGER_OPTS         |
| WebAppProxy                   | YARN_PROXYSERVER_OPTS         |
| Map Reduce Job History Server | HADOOP_JOB_HISTORYSERVER_OPTS |

例如，配置Namenode使用`parallelGC`，下面的部分可以添加到`hadoop_env.sh`中：

```shell
export HADOOP_NAMENODE_OPTS="-XX:+UseParallelGC"
```

查看`etc/hadoop/hadoop-env.sh`查看其他的例子。

你可以配置的其他非常有用的参数包含：

* `HADOOP_PID_DIR` - 这个目录存储守护进程的id文件
* `HADOOP_LOG_DIR` - 这个目录存储守护进程的日志文件，日志文件会被自动的创建。
* `HADOOP_HEAPSIZE` / `YARN_HEAPSIZE` - 最大可用的堆容量，单位`MB`。例如：如果该变量被设置为1000，那么堆的大小会被设置为1000M。它被用于配置守护进程的堆大小。默认值为1000

大多数情况下，你应该指定`HADOOP_PID_DIR`和`HADOOP_LOG_DIR`，他们仅能被运行Hadoop守护进程的用户进行写入操作。否则可能会发生符号链接攻击。

也可以在整个shell的环境变量中配置`HADOOP_PREFIX`。例如，在`/etc/profile.d`中的一段简单的脚本：

```shell
HADOOP_PREFIX=/path/to/hadoop
export HADOOP_PREFIX
```

设置各个守护进程堆大小的环境变量：

| 守护进程                      | 环境变量                          |
| ----------------------------- | --------------------------------- |
| ResourceManager               | YARN_RESOURCEMANAGER_HEAPSIZE     |
| NodeManager                   | YARN_NODEMANAGER_HEAPSIZE         |
| WebAppProxy                   | YARN_PROXYSERVER_HEAPSIZE         |
| Map Reduce Job History Server | HADOOP_JOB_HISTORYSERVER_HEAPSIZE |

### 配置守护进程

这个章节中详解了给定配置文件的重要的参数：

* `etc/hadoop/core-site.xml`

| 参数                | 值            | 备注                     |
| ------------------- | ------------- | ------------------------ |
| fs.defaultFS        | NameNode的URL | hdfs://host:port/        |
| io.file.buffer.size | 131072        | 队列文件读写缓冲区的大小 |

