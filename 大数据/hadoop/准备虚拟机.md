# 搭建Hadoop开发环境

## 虚拟机配置

### 修改IP

`/etc/sysconfig/network-scripts/ifcfg-eth0`

```shell
ONBOOT="yes"
BOOTPROTO="static"
# 修改为自己的ip,网关和dns
IPADDR="10.211.55.11"
GATEWAY="10.211.55.1"
DNS1="10.211.55.1"
```

### 修改主机名

`/etc/sysconfig/network`

```shell
NETWORKING=yes
HOSTNAME=box11
```

### 修改 host

`/etc/hosts`

```shell
10.211.55.11 box11
10.211.55.12 box12
10.211.55.13 box13
10.211.55.14 box14
10.211.55.15 box15
10.211.55.16 box16
```

### 创建用户

```shell
# 创建用户
useradd box
## 修改用户密码
passwd box
```

### 添加用户为root用户

`/etc/sudoers`

```shell
# 在 root    ALL=(ALL)       ALL 下面添加
box     ALL=(ALL)       ALL
```

### 配置用户组

通过用户组为用户增加操作权限, 一下所有操作的文件`root`组必须有权限操作

```shell
# 将box用户添加到root组中
gpasswd -a box root
```

### 暂时关闭防火墙

```shell
systemctl stop firewalld
systemctl disable firewalld
```

## 配置Java

解压文件

`tar -zxvf jdk-xxx.tar.gz`

配置环境变量, 编辑`/etc/profile`

```shell
export JAVA_HOME=jdk解压目录的绝对路径
export PATH=$PATH:$JAVA_HOME/bin
```

## 配置hadoop

解压文件

`tar -zxvf hadoop-xxx.tar.gz`

配置环境变量, 编辑`/etc/profile/`

```shell
export HADOOP_HOME=hadoop解压目录的绝对路径
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

### 单机模式

Hadoop在无需进行任何配置的情况下,默认为单机模式

### 伪分布式模式

#### 配置文件

`etc/hadoop/hadoop-env.sh`

```shell
# 将 JAVA_HOME=${JAVA_HOME} 替换为本机绝对路径
JAVA_HOME=java home的绝对路径
```

`etc/hadoop/core-site.xml`

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

`etc/hadoop/hdfs-site.xml`

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

#### 配置ssh免密登陆

1.检查ssh是否为免密登陆状态

```shell
$ ssh localhost
```

2.如果上一步需要输入密码,使用如下命令配置

```shell
$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
```

#### 执行

1.格式化namenode, 仅能执行一次

```shell
$ hdfs namenode -format
```

2.启动namenode守护进程

```shell
$ start-hdfs.sh
```

日志默认打印在`${HADOOP_HOME}/logs`下面

3.通过浏览器访问`http://localhost:50070`即可展示namenode的信息

4.关闭hdfs

```shell
stop-hdfs.sh
```

#### 配置yarn

`etc/hadoop/yarn-env.sh`

```shell
# 将 JAVA_HOME=${JAVA_HOME} 替换为本机绝对路径
JAVA_HOME=java home的绝对路径
```

`etc/hadoop/mapred-site.xml`

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

`etc/hadoop/yarn-site.xml`

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
  
    <property>
		    <name>yarn.resourcemanager.hostname</name>
		    <value>localhost</value>
    </property>
</configuration>
```

启动

```shell
start-yarn.sh
```

停止

```shell
stop-yarn.sh
```

